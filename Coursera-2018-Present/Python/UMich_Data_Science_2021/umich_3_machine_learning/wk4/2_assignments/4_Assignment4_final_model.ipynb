{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d250654b",
   "metadata": {},
   "source": [
    "# Assignment 4: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff431ca",
   "metadata": {},
   "source": [
    "### Reading in Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762406da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in test data\n",
    "blight_train = pd.read_csv('readonly/train.csv', engine='python')\n",
    "blight_test = pd.read_csv('readonly/test.csv')\n",
    "addresses = pd.read_csv('readonly/addresses.csv')\n",
    "latlons = pd.read_csv('readonly/latlons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e8f5b",
   "metadata": {},
   "source": [
    "## Cleaning Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a24db",
   "metadata": {},
   "source": [
    "#### Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e4848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 1: setting indices to ticket id\n",
    "blight_train = blight_train.set_index('ticket_id')\n",
    "addresses = addresses.set_index('ticket_id')\n",
    "\n",
    "# merge 1: merging on ticket id\n",
    "blight_train = pd.merge(blight_train, addresses, how = 'inner',\n",
    "                        left_index=True, right_index=True)\n",
    "\n",
    "# resetting index, to retain ticket id in data\n",
    "blight_train = blight_train.reset_index()\n",
    "\n",
    "# merge 2: setting address to upper case\n",
    "blight_train['address'] = blight_train['address'].str.upper()\n",
    "latlons['address'] = latlons['address'].str.upper()\n",
    "\n",
    "# merge 2: setting indices to address\n",
    "blight_train = blight_train.set_index('address')\n",
    "latlons = latlons.set_index('address')\n",
    "\n",
    "# merge 2: merging on address\n",
    "blight_train = pd.merge(blight_train, latlons, how = 'inner',\n",
    "                        left_index=True, right_index=True)\n",
    "\n",
    "# resetting index\n",
    "blight_train = blight_train.reset_index()\n",
    "blight_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffdd80",
   "metadata": {},
   "source": [
    "#### Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all variables only in training set\n",
    "no_feat = ['balance_due', 'collection_status', 'compliance_detail', 'payment_amount', 'payment_date', 'payment_status']\n",
    "blight_train.drop(no_feat, axis=1, inplace=True)\n",
    "blight_train.head()\n",
    "    \n",
    "# Dropping all unused categorical features\n",
    "cat_feat = ['address', 'city', 'disposition', 'grafitti_status', 'hearing_date', 'mailing_address_str_name', 'non_us_str_code', 'ticket_issued_date', 'violation_code', 'violation_street_name', 'violator_name', 'zip_code']\n",
    "blight_train.drop(cat_feat, axis=1, inplace=True)\n",
    "blight_train.head()\n",
    "    \n",
    "# Dropping all unused continuous features\n",
    "cont_feat = ['clean_up_cost', 'mailing_address_str_number', 'violation_street_number', 'violation_zip_code']\n",
    "blight_train.drop(cont_feat, axis=1, inplace=True)\n",
    "blight_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc11d5",
   "metadata": {},
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cda6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blight_train[[\"fine_amount\", \"admin_fee\", \"state_fee\", \"late_fee\", \"discount_amount\", \"judgment_amount\", \"compliance\", \"lat\", \"lon\"]] = blight_train[[\"fine_amount\", \"admin_fee\", \"state_fee\", \"late_fee\", \"discount_amount\", \"judgment_amount\", \"compliance\", \"lat\", \"lon\"]].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405bb5e",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values for state with 'MI', after verifying using address \n",
    "blight_train['state'] = np.where(blight_train['state'].isnull(), 'MI', blight_train['state'])\n",
    "    \n",
    "# replacing remaining nan's with 0 in dataframe\n",
    "blight_train = blight_train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83532469",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one hot encoding of column Agency Name\n",
    "one_hot = pd.get_dummies(blight_train['agency_name'])\n",
    "# Drop column Agency Name as it is now encoded\n",
    "blight_train = blight_train.drop('agency_name',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_train = blight_train.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of column Inspector Name\n",
    "one_hot = pd.get_dummies(blight_train['inspector_name'])\n",
    "# Drop column Inspector Name as it is now encoded\n",
    "blight_train = blight_train.drop('inspector_name',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_train = blight_train.join(one_hot)\n",
    "    \n",
    "# Get one hot encoding of column State\n",
    "one_hot = pd.get_dummies(blight_train['state'])\n",
    "# Drop column state as it is now encoded\n",
    "blight_train = blight_train.drop('state',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_train = blight_train.join(one_hot)\n",
    "    \n",
    "# Get one hot encoding of column Country\n",
    "one_hot = pd.get_dummies(blight_train['country'])\n",
    "# Drop column country as it is now encoded\n",
    "blight_train = blight_train.drop('country',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_train = blight_train.join(one_hot)\n",
    "\n",
    "# cleaning violation description\n",
    "blight_train['violation_description2'] = ''\n",
    "blight_train.loc[blight_train.violation_description2 == '', 'violation_description2'] = blight_train.violation_description.str.split().str.get(0)\n",
    "blight_train.drop(['violation_description'], axis=1, inplace=True)\n",
    "    \n",
    "# Get one hot encoding of column Violation Description\n",
    "one_hot = pd.get_dummies(blight_train['violation_description2'])\n",
    "# Drop column violation description 2 as it is now encoded\n",
    "blight_train = blight_train.drop('violation_description2',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_train = blight_train.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1ba8b",
   "metadata": {},
   "source": [
    "## Cleaning Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d127e",
   "metadata": {},
   "source": [
    "#### Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 1: setting indices to ticket id\n",
    "blight_test = blight_test.set_index('ticket_id')\n",
    "# addresses = addresses.set_index('ticket_id')\n",
    "\n",
    "# merge 1: merging on ticket id\n",
    "blight_test = pd.merge(blight_test, addresses, how = 'inner',\n",
    "                        left_index=True, right_index=True)\n",
    "\n",
    "# resetting index, to retain ticket id in data\n",
    "blight_test = blight_test.reset_index()\n",
    "\n",
    "# merge 2: setting address to upper case\n",
    "blight_test['address'] = blight_test['address'].str.upper()\n",
    "# latlons['address'] = latlons['address'].str.upper()\n",
    "\n",
    "# merge 2: setting indices to address\n",
    "blight_test = blight_test.set_index('address')\n",
    "# latlons = latlons.set_index('address')\n",
    "\n",
    "# merge 2: merging on address\n",
    "blight_test = pd.merge(blight_test, latlons, how = 'inner',\n",
    "                        left_index=True, right_index=True)\n",
    "\n",
    "# resetting index\n",
    "blight_test = blight_test.reset_index()\n",
    "blight_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba4ad8",
   "metadata": {},
   "source": [
    "#### Subsettting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d84465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all unused categorical features\n",
    "cat_feat = ['address', 'city', 'disposition', 'grafitti_status', 'hearing_date', 'mailing_address_str_name', 'non_us_str_code', 'ticket_issued_date', 'violation_code', 'violation_street_name', 'violator_name', 'zip_code']\n",
    "blight_test.drop(cat_feat, axis=1, inplace=True)\n",
    "blight_test.head()\n",
    "    \n",
    "# Dropping all unused continuous features\n",
    "cont_feat = ['clean_up_cost', 'mailing_address_str_number', 'violation_street_number', 'violation_zip_code']\n",
    "blight_test.drop(cont_feat, axis=1, inplace=True)\n",
    "blight_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b6e00c",
   "metadata": {},
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "blight_test[[\"fine_amount\", \"admin_fee\", \"state_fee\", \"late_fee\", \"discount_amount\", \"judgment_amount\", \"lat\", \"lon\"]] = blight_test[[\"fine_amount\", \"admin_fee\", \"state_fee\", \"late_fee\", \"discount_amount\", \"judgment_amount\", \"lat\", \"lon\"]].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bc73f",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b6dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values for state with 'MI', after verifying using address \n",
    "blight_test['state'] = np.where(blight_test['state'].isnull(), 'MI', blight_test['state'])\n",
    "    \n",
    "# replacing remaining nan's with 0 in dataframe\n",
    "blight_test = blight_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3593f",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c575a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one hot encoding of column Agency Name\n",
    "one_hot = pd.get_dummies(blight_test['agency_name'])\n",
    "# Drop column Agency Name as it is now encoded\n",
    "blight_test = blight_test.drop('agency_name',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_test = blight_test.join(one_hot)\n",
    "    \n",
    "# Get one hot encoding of column Inspector Name\n",
    "one_hot = pd.get_dummies(blight_test['inspector_name'])\n",
    "# Drop column Inspector Name as it is now encoded\n",
    "blight_test = blight_test.drop('inspector_name',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_test = blight_test.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of column State\n",
    "one_hot = pd.get_dummies(blight_test['state'])\n",
    "# Drop column state as it is now encoded\n",
    "blight_test = blight_test.drop('state',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_test = blight_test.join(one_hot)\n",
    "    \n",
    "# Get one hot encoding of column Country\n",
    "one_hot = pd.get_dummies(blight_test['country'])\n",
    "# Drop column country as it is now encoded\n",
    "blight_test = blight_test.drop('country',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_test = blight_test.join(one_hot)\n",
    "\n",
    "# cleaning violation description\n",
    "blight_test['violation_description2'] = ''\n",
    "blight_test.loc[blight_test.violation_description2 == '', 'violation_description2'] = blight_test.violation_description.str.split().str.get(0)\n",
    "blight_test.drop(['violation_description'], axis=1, inplace=True)\n",
    "    \n",
    "# Get one hot encoding of column Violation Description\n",
    "one_hot = pd.get_dummies(blight_test['violation_description2'])\n",
    "# Drop column violation description 2 as it is now encoded\n",
    "blight_test = blight_test.drop('violation_description2',axis = 1)\n",
    "# Join the encoded df\n",
    "blight_test = blight_test.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e221346",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ac2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = blight_train.drop('compliance', axis=1)\n",
    "labels = blight_train['compliance']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "lr_predicted = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52990f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_lr = lr.fit(X_train, y_train).decision_function(X_test)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc43259",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_lr = lr.fit(X_train, y_train).predict_proba(X_test)\n",
    "y_proba_list = list(zip(lr_predicted[0:20], y_proba_lr[0:20,1]))\n",
    "  \n",
    "df = pd.DataFrame(y_proba_lr, X_test['ticket_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e03ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5b4aa",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(list(blight_train.columns)).intersection(list(blight_test.columns)))\n",
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = blight_train.drop('compliance', axis=1)\n",
    "features = features[intersection]                                                    \n",
    "labels = blight_train['compliance']\n",
    "\n",
    "blight_test = blight_test[intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(features, labels)\n",
    "lr_predicted = lr.predict(blight_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_lr = lr.fit(features, labels).decision_function(blight_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ce1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_lr = lr.fit(features, labels).predict_proba(blight_test)\n",
    "y_proba_list = list(zip(lr_predicted[0:20], y_proba_lr[0:20,1]))\n",
    "  \n",
    "df = pd.DataFrame(y_proba_lr, blight_test['ticket_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9740b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127f2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
